{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fce735-5e75-4ba4-8507-4e8b954f52c0",
   "metadata": {},
   "source": [
    "# Implement Precision, Recall, and Prediction Error in Binary Classification\n",
    "\n",
    "## Task: Implement Precision, Recall, and Prediction Error in Binary Classification\n",
    "\n",
    "Your task is to implement three key metrics in a binary classification setting:  \n",
    "\n",
    "- **Precision**: Measures the proportion of correctly predicted positive instances among all predicted positive instances.  \n",
    "- **Recall**: Measures the proportion of correctly predicted positive instances among all actual positive instances.  \n",
    "- **Prediction Error**: Measures the proportion of incorrect predictions (both false positives and false negatives) relative to the total number of predictions.  \n",
    "\n",
    "You need to write a function `precision_recall_error(y_true, y_pred)` that computes all three metrics. The function should accept two inputs:  \n",
    "\n",
    "- `y_true`: A list of true binary labels (0 or 1) for the dataset.  \n",
    "- `y_pred`: A list of predicted binary labels (0 or 1) from the model.  \n",
    "\n",
    "Your function should return a tuple **(precision, recall, prediction_error)**, all rounded to **three decimal places**.  \n",
    "\n",
    "- If the denominator in **Precision (TP + FP)** is zero, return **0.0** for precision to avoid division by zero.  \n",
    "- If the denominator in **Recall (TP + FN)** is zero, return **0.0** for recall to avoid division by zero.  \n",
    "\n",
    "---\n",
    "\n",
    "## Example:\n",
    "\n",
    "### **Input:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([1, 0, 1, 1, 0, 1])\n",
    "y_pred = np.array([1, 0, 1, 0, 1, 1])\n",
    "\n",
    "print(precision_recall_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393b7f40-8b93-4e8d-a2d2-36dc8677c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_error(y_true, y_pred):\n",
    "    # TP \n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    # FP\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    # TN\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    # FN\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    \n",
    "    # precision: TP / TP + FP\n",
    "    precision = TP / (TP + FP) if TP + FP else 0\n",
    "    \n",
    "    # recall: TP / TP + FN\n",
    "    recall = TP / (TP + FN) if TP + FN else 0\n",
    "\n",
    "    # prediction error: \n",
    "    pred_error = np.sum(y_true != y_pred) / len(y_true)\n",
    "\n",
    "    return precision, recall, pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f51791b-84ad-423a-b8de-e0d0bc3f0714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.75, 0.75, 0.3333333333333333)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.array([1, 0, 1, 1, 0, 1])\n",
    "y_pred = np.array([1, 0, 1, 0, 1, 1])\n",
    "\n",
    "print(precision_recall_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01a1a8-f7c4-415e-ba81-b1d490cc03a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
