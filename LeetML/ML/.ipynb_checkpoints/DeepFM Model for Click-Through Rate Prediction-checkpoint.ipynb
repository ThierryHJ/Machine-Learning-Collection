{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76433a93-9309-425d-9fa3-73f23f5e4026",
   "metadata": {},
   "source": [
    "# DeepFM Model for Click-Through Rate Prediction\n",
    "\n",
    "## Problem Statement\n",
    "You are given a dataset for **Click-Through Rate (CTR) prediction**, which includes both **categorical and numerical features**. Your task is to **implement the DeepFM model** and train it on the provided dataset.\n",
    "\n",
    "**DeepFM** is a recommendation model that combines:\n",
    "- **Factorization Machines (FM)** for capturing **low-order feature interactions**.\n",
    "- **A deep neural network (DNN)** for capturing **high-order feature interactions**.\n",
    "\n",
    "### **Mathematical Formulation of DeepFM**\n",
    "Given an input feature vector \\( x \\), the DeepFM model consists of:\n",
    "\n",
    "#### **1. Linear Component (FM Part)**\n",
    "The **linear term** of FM captures independent feature contributions:\n",
    "$$y_{\\text{linear}} = w_0 + \\sum_{i=1}^{n} w_i x_i$$\n",
    "where \\( w_0 \\) is the global bias, and \\( w_i \\) is the weight for feature \\( x_i \\).\n",
    "\n",
    "#### **2. Factorization Machine (FM) Component**\n",
    "The FM component models pairwise feature interactions using latent factor embeddings:\n",
    "$$y_{\\text{FM}} = \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=i+1}^{n} \\langle v_i, v_j \\rangle x_i x_j$$\n",
    "where \\( v_i \\) and \\( v_j \\) are the learned embedding vectors for features \\( i \\) and \\( j \\).\n",
    "\n",
    "An alternative formulation:\n",
    "$$y_{\\text{FM}} = \\frac{1}{2} \\sum_{i=1}^{n} \\left( \\sum_{j=1}^{k} v_{ij} x_j \\right)^2 - \\sum_{j=1}^{k} v_{ij}^2 x_j^2$$\n",
    "captures second-order interactions efficiently.\n",
    "\n",
    "#### **3. Deep Neural Network (DNN) Component**\n",
    "The **DNN** component models higher-order feature interactions:\n",
    "\n",
    "\n",
    "#### **4. Final Prediction Layer**\n",
    "The final output of DeepFM is computed as:\n",
    "$$y_{\\text{hat}} = \\sigma(y_{\\text{linear}} + y_{\\text{FM}} + y_{\\text{DNN}})$$\n",
    "where \\( \\sigma \\) is the **sigmoid function** that outputs the probability of a click.\n",
    "\n",
    "## **Instructions**\n",
    "You need to complete the following sections in the given Python script:\n",
    "\n",
    "1. **Implement the DeepFM model architecture** (`DeepFM` class).\n",
    "2. **Implement the training loop** (`train_model` function).\n",
    "3. **Ensure the model is trainable on the given dataset**.\n",
    "\n",
    "Your implementation should:\n",
    "- Implement the **FM and DNN components**.\n",
    "- Combine both components in a final **prediction layer**.\n",
    "- Train the model on the given dataset.\n",
    "\n",
    "üöÄ **Now, implement the missing parts and build the DeepFM model for CTR prediction!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e8fcde-05a2-4aff-a26c-ecfdc6c2ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torchkeras import summary, kerasmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9baf4b-3394-4d9f-887b-8c902a94ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size=1):\n",
    "        super(DNN, self).__init__()\n",
    "        # initiate layers\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # iterate hidden_layers and activations, append to layers\n",
    "        for i in range(len(hidden_layers)):\n",
    "            layers.append(nn.Linear(prev_size, hidden_layers[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_layers[i]\n",
    "\n",
    "        # nn.Sequential(*layers)\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class FM(nn.Module):\n",
    "    def __init__(self, feature_size, latent_size):\n",
    "        super(FM, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.b = nn.Parameter(torch.zeros([1, ]))\n",
    "        self.w1 = nn.Parameter(torch.randn([feature_size, 1]))\n",
    "        self.w2 = nn.Parameter(torch.randn([feature_size, latent_size]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        first_order = torch.matmul(x, self.w1) + self.b\n",
    "        second_order = 1/2 * torch.sum( \\\n",
    "                                (torch.pow(torch.matmul(x, self.w2), 2) - \\\n",
    "                                 torch.matmul(torch.pow(x, 2), torch.pow(self.w2, 2))), dim=1, keepdim=True)\n",
    "        return first_order + second_order\n",
    "        \n",
    "\n",
    "# DeepFM Model (Fill in the missing parts)\n",
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units, activations):\n",
    "        super(DeepFM, self).__init__()\n",
    "        # TODO: Implement network layers\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.DNN = DNN(input_dim, hidden_units)\n",
    "        self.FM = FM(input_dim, latent_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        # ÊääÁ¶ªÊï£ÁâπÂæÅÂíåËøûÁª≠ÁâπÂæÅËøõË°åÊãºÊé•‰Ωú‰∏∫FMÂíåDNNÁöÑËæìÂÖ•\n",
    "        # wide\n",
    "        wide_outputs = self.FM(x)\n",
    "        # deep\n",
    "        deep_outputs = self.DNN(x)\n",
    "        output = self.sigmoid(torch.add(wide_outputs, deep_outputs)).view(-1)\n",
    "        return output\n",
    "        \n",
    "\n",
    "# Training Function (Fill in the missing parts)\n",
    "def train_model(model, train_loader, num_epochs=5, lr=0.001):\n",
    "    # TODO: Define loss function and optimizer\n",
    "    loss = nn.BCEloss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            predictions = model(X_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d6b541e-2fbe-459a-8428-c05874e853a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 128\n",
    "hidden_units = [64, 32]\n",
    "latent_dim = 10\n",
    "model = DeepFM(input_dim, hidden_units, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328da62d-1636-4299-a79e-459db2118ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "FM-1                                         [-1, 1]                1,409\n",
      "Linear-2                                    [-1, 64]                8,256\n",
      "ReLU-3                                      [-1, 64]                    0\n",
      "Linear-4                                    [-1, 32]                2,080\n",
      "ReLU-5                                      [-1, 32]                    0\n",
      "Linear-6                                     [-1, 1]                   33\n",
      "Sigmoid-7                                    [-1, 1]                    0\n",
      "==========================================================================\n",
      "Total params: 11,778\n",
      "Trainable params: 11,778\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000488\n",
      "Forward/backward pass size (MB): 0.001488\n",
      "Params size (MB): 0.044930\n",
      "Estimated Total Size (MB): 0.046906\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'--------------------------------------------------------------------------\\nLayer (type)                            Output Shape              Param #\\n==========================================================================\\nFM-1                                         [-1, 1]                1,409\\nLinear-2                                    [-1, 64]                8,256\\nReLU-3                                      [-1, 64]                    0\\nLinear-4                                    [-1, 32]                2,080\\nReLU-5                                      [-1, 32]                    0\\nLinear-6                                     [-1, 1]                   33\\nSigmoid-7                                    [-1, 1]                    0\\n==========================================================================\\nTotal params: 11,778\\nTrainable params: 11,778\\nNon-trainable params: 0\\n--------------------------------------------------------------------------\\nInput size (MB): 0.000488\\nForward/backward pass size (MB): 0.001488\\nParams size (MB): 0.044930\\nEstimated Total Size (MB): 0.046906\\n--------------------------------------------------------------------------'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_shape=(input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cb9914-5aa3-41cf-afb2-0fa1cc17af0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/data/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m train_df, y_train \u001b[38;5;241m=\u001b[39m preprocess_data(train_df)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Create DataLoaders\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(train_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(train_path):\n\u001b[0;32m---> 11\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Drop ID column\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     train_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/train.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "def load_data(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    \n",
    "    # Drop ID column\n",
    "    train_df.drop(columns=['Id'], inplace=True)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train_df):\n",
    "    # Separate labels\n",
    "    y_train = train_df['Label'].fillna(0).astype(int).values\n",
    "    train_df = train_df.drop(columns=['Label'])\n",
    "    \n",
    "    # Fill missing numerical values with 0\n",
    "    num_features = [col for col in train_df.columns if col.startswith(\"I\")]\n",
    "    train_df[num_features] = train_df[num_features].fillna(0)\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    train_df[num_features] = scaler.fit_transform(train_df[num_features])\n",
    "    \n",
    "    # Encode categorical features\n",
    "    cat_features = [col for col in train_df.columns if col.startswith(\"C\")]\n",
    "    for col in cat_features:\n",
    "        train_df[col].fillna(\"missing\", inplace=True)\n",
    "        le = LabelEncoder()\n",
    "        train_df[col] = le.fit_transform(train_df[col])\n",
    "    \n",
    "    return train_df, y_train\n",
    "\n",
    "# PyTorch Dataset Class\n",
    "class CTRDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "train_df = load_data(\"/mnt/data/train.csv\")\n",
    "train_df, y_train = preprocess_data(train_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = CTRDataset(train_df, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "input_dim = train_df.shape[1]\n",
    "hidden_units = [64, 32]\n",
    "latent_dim = 10\n",
    "model = DeepFM(input_dim, hidden_units, latent_dim)\n",
    "\n",
    "# Train model\n",
    "model = train_model(model, train_loader, num_epochs=5, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf9350-8953-405f-8bf3-8d93e185ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
